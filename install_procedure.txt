1.下载如下软件包
    CentOS7, 
    Hadoop2.7.3,
    JDK1.8.0  （Linux rpm文件）
    Vmware16,
    XShell,
    FileZille,

2 安装3个虚拟机并实现ssh免密码登录
  2.1安装3个机器虚拟机master,（slave1,slave2可以由master克隆而来）
     
     注意点：一个是software selection(选择infrastructure server)，一个是network &host name默认是选中Minimal Install，
     这个安装之后很多东西要自己手动安装和配置，麻烦，建议不选这个，如果你喜欢桌面，你还可以选择 GNOME  Desktop我这里不要桌面，我选的是Server。
     
     设置ROOT用户的密码。
     
     安装完成后，重启，使用账户密码登录，然后用ifconfig命令查看IP配置。
     
     Xshell进行远程连接。
     
     说明：如果在安装时候选择的是Minimal  Install或者是没有选择Network & host name进行相关配置，ssh服务是没有安装的，
     也就没法使用远程工具进行连接。此时你需要用root账户登录，或者使用普通账户登录后用sudo命令获得管理员权限，安装ssh服务。
     
     查看ssh服务状态的命令：
     service  sshd  status
     
   2.2检查机器名称
     hostname #查看
     hostnamectl set-hostname master #永久修改hostname为master
     systemctl   stop   firewalld #关闭防火墙
     systemctl   disable   firewalld #永久关闭
   
   2.3 修改/etc/hosts文件, #3台机器同时进行
       vi /etc/hosts
       #修改为
       192.168.234.132   master  
       192.168.234.131   slave1  
       192.168.234.130   slave2
       
       用Xshell远程登录三台虚拟机，互相ping命令检查这3个机器是否相互ping得通。
    
    2.4给3个机器生成秘钥文件, #3台机器同时进行
      ssh-keygen  -t   rsa   -P  ''  
      ls    /root/.ssh/
    
    2.5在3台机器上创建authorized_keys文件
      cat id_rsa.pub   #分别查看master，slave1, slave2的公钥
      vi /root/.ssh/authorized_keys   #三台机器的公钥合在一起写进authorized_keys中，3台机器同时进行，此时三台机器都有了authorized_keys文件了
    
    2.6测试使用ssh进行无密码登录
      ssh master
      ssh slave1
      ssh slave2   #首次会需要输入密码
 
3 安装jdk和hadoop
    3.1 安装JDK
      
      把rpm压缩包放在/usr/local/目录下。    #/usr/local/相当于Windows的C：/progarm files/
      
      rpm -ivh jdk-8u91-linux-x64.rpm    #会自动解压缩到/usr/java/路径
      
      vi /etc/profile  #配置java环境变量
      export JAVA_HOME=/usr/java/jdk1.8.0_121
      export CLASSPATH=$:CLASSPATH:$JAVA_HOME/lib/
      export PATH=$PATH:$JAVA_HOME/bin
      source /etc/profile #编译
      
      
    3.2  安装hadoop
      注意！！！！！！： 3台机器上都需要重复下面（3.2）所讲的步骤。
      
      3.2.1 上载文件并解压缩
          把hadoop-2.7.3.tar.gz安装包放在/usr/local/目录下，
          cd /usr/lcoal/
          tar -xvf hadoop-2.7.3.tar.gz  #解压缩，解压缩到/usr/local/路径下
          mv hadoop-2.7.3 hadoop #修改压缩文件夹hadoop-2.7.3的名称为hadoop
          
          vi /etc/profile  #配置hadoop环境变量
          export PATH=$PATH:/usr/local/hadoop/bin:/usr/local/hadoop/sbin
          source /etc/profile #编译
          
      3.2.2新建几个目录
         mkdir  /root/hadoop  
         mkdir  /root/hadoop/tmp  
         mkdir  /root/hadoop/var  
         mkdir  /root/hadoop/dfs  
         mkdir  /root/hadoop/dfs/name  
         mkdir  /root/hadoop/dfs/data  
      
      3.2.3 修改etc/hadoop中的一系列配置文件
         cd /usr/local/hadoop/etc/hadoop/
         
         3.2.3.1 修改core-site.xml
         vi /usr/local/hadoop/etc/hadoop/core-site.xml
         <property>
            <name>hadoop.tmp.dir</name>
            <value>/root/hadoop/tmp</value>
            <description>Abase for other temporary directories.</description>
        </property>
        <property>
            <name>fs.default.name</name>
            <value>hdfs://master:9000</value>
        </property>
        
        3.2.3.2 修改hadoop-env.sh
        vi /usr/local/hadoop/etc/hadoop/hadoop-env.sh
        export   JAVA_HOME=/usr/java/default
        
        3.2.3.3 修改hdfs-site.xml
        vi /usr/local/hadoop/etc/hadoop/hdfs-site.xml
        <property>
           <name>dfs.name.dir</name>
           <value>/root/hadoop/dfs/name</value>
           <description>Path on the local filesystem where theNameNode stores the namespace and transactions logs persistently.            </description>
       </property>
       <property>
           <name>dfs.data.dir</name>
           <value>/root/hadoop/dfs/data</value>
           <description>Comma separated list of paths on the localfilesystem of a DataNode where it should store its blocks.                </description>
       </property>
       <property>
           <name>dfs.replication</name>
           <value>2</value>
       </property>
       
       3.2.3.4 新建并且修改mapred-site.xml
       mv  /usr/local/hadoop/etc/hadoop/mapred-site.xml.template /usr/local/hadoop/etc/hadoop/mapred-site.xml #改文件名
       vi /usr/local/hadoop/etc/hadoop/mapred-site.xml
       <property>
            <name>mapred.job.tracker</name>
            <value>master:49001</value>
       </property>
       <property>
           <name>mapred.local.dir</name>
           <value>/root/hadoop/var</value>
       </property>
       <property>
           <name>mapreduce.framework.name</name>
           <value>yarn</value>
       </property>
       
       3.2.3.5 修改slaves文件
       vi /usr/local/hadoop/etc/hadoop/slaves #添加如下
       slave1
       slave2
       
       3.2.3.6 修改yarn-site.xml文件
       vi /usr/local/hadoop/etc/hadoop/yarn-site.xml
       <property>
             <name>yarn.resourcemanager.hostname</name>
             <value>master</value>
       </property>
       <property>
            <description>The address of the applications manager interface in the RM.</description>
            <name>yarn.resourcemanager.address</name>
            <value>${yarn.resourcemanager.hostname}:8032</value>
       </property>
       <property>
            <description>The address of the scheduler interface.</description>
            <name>yarn.resourcemanager.scheduler.address</name>
            <value>${yarn.resourcemanager.hostname}:8030</value>
       </property>
       <property>
            <description>The http address of the RM web application.</description>
            <name>yarn.resourcemanager.webapp.address</name>
            <value>${yarn.resourcemanager.hostname}:8088</value>
       </property>
       <property>
            <description>The https adddress of the RM web application.</description>
            <name>yarn.resourcemanager.webapp.https.address</name>
            <value>${yarn.resourcemanager.hostname}:8090</value>
       </property>
       <property>
            <name>yarn.resourcemanager.resource-tracker.address</name>
            <value>${yarn.resourcemanager.hostname}:8031</value>
       </property>
       <property>
            <description>The address of the RM admin interface.</description>
            <name>yarn.resourcemanager.admin.address</name>
            <value>${yarn.resourcemanager.hostname}:8033</value>
       </property>
       <property>
            <name>yarn.nodemanager.aux-services</name>
            <value>mapreduce_shuffle</value>
       </property>
       <property>
            <name>yarn.scheduler.maximum-allocation-mb</name>
            <value>2048</value>
            <discription>每个节点可用内存,单位MB,默认8182MB</discription>
       </property>
       <property>
            <name>yarn.nodemanager.vmem-pmem-ratio</name>
            <value>2.1</value>
        </property>
        <property>
            <name>yarn.nodemanager.resource.memory-mb</name>
            <value>2048</value>
        </property>
        <property>
            <name>yarn.nodemanager.vmem-check-enabled</name>
            <value>false</value>
        </property>
        
4 启动hadoop  #只需要对master操作
   4.1在namenode上执行初始化  
     因为master是namenode，slave1和slave2都是datanode，所以只需要对master进行初始化操作，也就是对hdfs进行格式化。
     
     #cd /usr/local/hadoop/bin
     #./hadoop namenode -format  #初始化，/root/hadoop/dfs/name/目录多了一个current目录
     或者：
     hdfs namenode -format
   
   4.2在namenode上执行启动命令
     cd /usr/local/hadoop/sbin
     ./start-all.sh   #这个命令master，slave1，slave2都会启动
     #hadoop-daemon.sh start namenode  在master在启动namenode
     #hadoop-daemon.sh start datanode  在slave1在启动datanode
     jps #查看进程

master是我们的namanode，该机器的IP是192.168.234.132，在本地电脑访问如下地址: 
http://192.168.234.132:50070/  #overview页面
http://192.168.234.132:8088/    #cluster页面
          









